{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e38b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import normalize\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Module\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from torch.nn.utils import parametrize\n",
    "from einops import rearrange\n",
    "import math\n",
    "import random\n",
    "from Modules import *\n",
    "from FourierModules import *\n",
    "from utils import *\n",
    "from DiffAugment import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn  \n",
    "import numpy as np\n",
    "#32x32 on Cifar-10 \n",
    "#64×64 on CelebA\n",
    "#128×128 on LSUN bedroom\n",
    "#torch.zeros(34,12,51,16) + torch.ones(1,12,51,1) Marche\n",
    "#torch.zeros(34,12,51,16) + torch.ones(12,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be3da376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulatedLinear1(nn.Module):\n",
    "    def __init__(self, in_features, out_features, demodulation=True):\n",
    "        super(ModulatedLinear1, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = 1 / math.sqrt(in_features)\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))        \n",
    "        self.demodulation = demodulation\n",
    "\n",
    "\n",
    "    def forward(self, Efou, y):\n",
    "        #Efou ->(BxL,PxP,E)\n",
    "        #y -> (B, L, E)\n",
    "        #groups in conv1d apply in each num_peatches\n",
    "        #Weight ->(out_features, in_features)\n",
    "        #y -> (batch_size, 1, self.in_features)\n",
    "        batch_size = Efou.shape[0]\n",
    "        y = y.view(batch_size, 1, self.in_features) #(BxL,1,in_features)\n",
    "        weight = self.scale * self.weight * y\n",
    "\n",
    "        if self.demodulation:\n",
    "            dconf = torch.rsqrt(weight.pow(2).sum(dim = 2) + 1e-8)\n",
    "            weight = weight * dconf.view(batch_size, self.out_features, 1) # batch, out_features, in_features\n",
    "\n",
    "        weight = weight.view(batch_size * self.out_features, self.in_features, 1)\n",
    "\n",
    "        size_patch = Efou.size(1)\n",
    "        Efou = Efou.reshape(1, batch_size * self.in_features, size_patch)\n",
    "        x = F.conv1d(Efou, weight, groups=batch_size)\n",
    "        x = x.view(batch_size, size_patch, self.out_features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a8cf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6400, 16, 240])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModulatedLinear1(240,240)(torch.randn(100*64,16, 240), torch.randn(100,64,240)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e932c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulatedLinear2(nn.Module):\n",
    "    def __init__(self, in_features, out_features, demodulation=True):\n",
    "        super(ModulatedLinear2, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = 1 / math.sqrt(in_features)\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features))        \n",
    "        self.demodulation = demodulation\n",
    "\n",
    "\n",
    "    def forward(self, Efou, y):\n",
    "        #Efou ->(BxL,PxP,E)\n",
    "        #y -> (B, L, E)\n",
    "        #groups in conv1d apply in each num_peatches\n",
    "        #Weight ->(out_features, in_features)\n",
    "        #y -> (batch_size, 1, self.in_features)\n",
    "        batch_size = Efou.shape[0] #(BxL)\n",
    "        y = y.view(batch_size, self.in_features, 1) #(BxL,in_features,1)\n",
    "        weight = self.scale * self.weight * y #(BxL,in_features,1) * (in_features,out_features)=> (BxL,in_features,out_features)\n",
    "\n",
    "        if self.demodulation:\n",
    "            dconf = torch.rsqrt(weight.pow(2).sum(dim = 1) + 1e-8) #(BxL, 1,out_features)\n",
    "            weight = weight * dconf.view(batch_size, 1, self.out_features) # BxL, in_features, out_features\n",
    "\n",
    "        #Ce que je veux Efou * weight\n",
    "        x = torch.matmul(Efou, weight)#(BxL,PxP,E) x (BxL, in_features, out_features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c8b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6400, 16, 240])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModulatedLinear2(240,240)(torch.randn(100*64,16, 240), torch.randn(100,64,240)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv2d') != -1:\n",
    "            if args.init_type == 'normal':\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif args.init_type == 'orth':\n",
    "                nn.init.orthogonal_(m.weight.data)\n",
    "            elif args.init_type == 'xavier_uniform':\n",
    "                nn.init.xavier_uniform(m.weight.data, 1.)\n",
    "            else:\n",
    "                raise NotImplementedError('{} unknown inital type'.format(args.init_type))\n",
    "\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
